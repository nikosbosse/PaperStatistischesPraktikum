\chapter{The Data}

\section{Stock Selection}
The stock data comprises 10 selected companies from the NASDAQ stock index. The stocks were determined as those are the stocks we have Ravenpack data and analyst reports about. 


\section{Ravenpack Sentiment Data}


\section{Analyst Reports}


\section{Stock Data}
\subsection{Overview over the Stock Data}
The stock data were downloaded from Yahoo Financial Data Base. Table \ref{tab:stocks_overview} provides a small overview over the raw data. Figure \ref{fig:Daily Stock Prices for all Stocks in the Data Set} shows the Closing Prices of the selected assets. The closing prices have been provided adjusted for dividends by Yahoo. Time series analysis is easiest with data that are at least weakly stationary. Weak stationarity implies that the mean of the time series is constant over time and that the covariance between two observations $y_t$ and $y_{t+h}$ depends only on h, not on t (see [Shumway and Stoffer 2011]). 

\begin{table}[]
    \figuretitle{Stock Data}
    \centering
    \begin{adjustbox}{width = 0.9\linewidth}
    \setlength{\tabcolsep}{15pt}
    \input{figures/table_overview_stocks2.tex}
    \end{adjustbox}
    \caption{}
    \label{tab:stocks_overview}
\end{table}{}

\begin{figure}[h]
    \figuretitle{Stock Prices}
    \centering
    \begin{adjustbox}{width=.9\textwidth,center}
    \input{figures/all_in_one_daily_stock_prices.pgf}
    \end{adjustbox}  
    \caption{Time series of the adjusted closing prices of all 10 stocks looked at in this paper}
    \label{fig:Daily Stock Prices for all Stocks in the Data Set}
\end{figure}{}

From figure \ref{fig:Daily Stock Prices for all Stocks in the Data Set} it can be clearly seen that most of the stocks exhibit a strong trend. Also the variance of most stocks increases steadily with time over the observed period. This increase in variance is illustrated in figure \ref{fig:cum_sd_all} where the standard deviation of the time series is shown. The data are therefore clearly not stationary. We can also formally test for stationarity using the augmented Dickey-Fuller test [REFERENCE]. This test, applied to all time series in no case is able to reject the null hypothesis of a unit root (implying non-stationarity) at any reasonable confidence level. 

\begin{figure}[H]
    \figuretitle{'Cumulative' Standard Deviation of Stock Prices}
    \centering
    \begin{adjustbox}{width=.9\textwidth,center}
    \input{figures/cum_sd_all_stocks.pgf}
    \end{adjustbox}  
    \caption{Standard deviation for the time series of stock prices. The value of the graph at point t is calculated as the standard deviation of all recorded values of the respective stocks up to that point t.}
    \label{fig:cum_sd_all}
\end{figure}{}

\subsection{Data Transformation}

In order to obtain weakly stationary time series the data needs to be transformed. There are different ways to proceed that are often equivalent or very similar to each other. Economists usually work with either returns or log-returns, albeit the nomenclature may be a bit confusing. (Daily) returns can be calculated as
\begin{equation*}
    r^{\scriptscriptstyle{(1)} }_t = \frac{r_t}{r_{t-1}} \qquad \text{or as} \qquad r^{\scriptscriptstyle{(2)}}_t = \frac{r_t - r_{t-1}}{r_{t-1}} = r^{\scriptscriptstyle{(1)}}_t - 1
\end{equation*}{}
Usually $r^{\scriptscriptstyle{(2)}}_t$ is used and is called either returns or log-returns, even though no logging takes place. For increased conceptual clarity, $r^{\scriptscriptstyle{(1)}}_t$ will be called returns and $log(r^{\scriptscriptstyle{(1)}}_t)$ will be called log-returns. $r^{\scriptscriptstyle{(2)}}_t$ will not be explicitly used. Log-returns are computationally convenient and numerically stable. For very small values they are also very close to the returns $r^{\scriptscriptstyle{(2)}}_t$ often used in economic literature as $ \log(r^{\scriptscriptstyle{(1)}}_t) \approx r^{\scriptscriptstyle{(1)}}_t - 1 = r^{\scriptscriptstyle{(2)}}_t$ for values of $r^{\scriptscriptstyle{(1)}}_t$ close to 1. Using returns or log-returns instead of stock prices can make the time series stationary. Figure \ref{fig:returns_all_stocks} illustrates that the trends in the time series have vanished after looking at log-returns. The data visually now looks like white noise. 

\begin{figure}[H]
    \figuretitle{Log-returns of stock PG}
    \centering
    \begin{adjustbox}{width=.9\textwidth,center}
    \input{figures/PG_fd_log_adjclose.pgf}
    \end{adjustbox}  
    \caption{Log-returns (or equivalently, first differences of the log of adjusted closing prices) of the PG. Visually the data looks similar to white noise. The entire data can be seen in the appendix in figure \ref{fig:all_fd_log_adjclose}}
    \label{fig:PG_fd_log_adjclose}
\end{figure}{}

That this is indeed a suitable transformation can be more intuitively understood by looking at a different route of transforming the data: taking the log of the stock prices and then using the first difference of the logged time series. Logging the time series transforms an exponential trend in the time series into a linear one and also serves to stabilize the variance. However, the trend does not vanish and after the log-transformation, the log value of a stock at time t is still mostly determined by its log-value at time t-1. To remove this effect, the time series needs to be differenced. To put this into a clearer perspective we can look at the autocorrelation and partial autocorrelation function of the series. 

The autocorrelation at lag j is the correlation between an observation at time t with the observation at t-j. As the series is assumed to be stationary, the autocorrelation function (ACF) does not depend on t, but only on the number of periods that lie between one observation $y_t$ and another $y_{t+h}$
\begin{equation}
    \text{ACF}(h) = corr(y_t, y_{t+h})
\end{equation}{}
Partial autocorrelation between an observation $y_t$ and another observation $y_{t+1}$ is the correlation between $y_t$ and $y_{t+h}$ that is not already explained by a linear dependence on the observations in between $y_t$ and $y_{t+h}$. Formally this can be defined as
\begin{equation}
    \text{PACF}(h) = corr(y_t - \hat{y}_t, y_{t+h} - \hat{y}_{t+h})
\end{equation}
\begin{flalign*}
    &\text{where} && \hat{y}_{t + h} = \beta_1 y_{t+h-1} + \beta_2 y_{t+h-2} + ... + \beta_{h-1} y_{t+1} &&\\
    &\text{and} && \hat{y_t} = \beta_1 y_{t+1} + \beta_2 y_{t+2} + ... + \beta_{h-1} y_{t+h-1} &&
\end{flalign*}{}
are the linear combinations $\{ y_{t+1}, ..., y_{t+h-1} \}$ that minimize the mean squared error of a regression of $y_{t+h}$, and $y_t$ respectively, on $\{ y_{t+1}, ..., y_{t+h-1}\}$. Both $y_t - \hat{y_t}$ and  $y_{t+h} - \hat{y}_{t+h}$ are uncorrelated with $\{ y_{t+1}, ..., y_{t+h-1} \}$. For now, however, it suffices to know that an ACF which is very slowly decaying to zero is an indicator that differencing may be appropriate (see Shumway and Stoffer 2011, p. 145) to make the series stationary. A large partial autocorrelation at lag 1, as shown in figure \ref{fig:acf_pacf_log_adjclose} also supports the conjecture that the dependence of the current on the previous value can be eliminated through differencing. After differencing we arrive again at the log-returns as $ \log{r^{\scriptscriptstyle{(1)}}_t} = \log{\frac{y_t}{y_{t-1}}} = \log{y_t} - \log{y_{t-1}} $. We can see now that the the partial autocorrelation at lag 1 has vanished after differecing and that the autocorrelation has also dropped to insignificance as is illustrated in figure \ref{fig:PG_autocorr_fd_log_adjclose}. We can also see that we have not induced any negative autocorrelation. The data therefore is not overdifferenced. The means of our time series is very close to zero (as shown in table \ref{tab:log return means}). Overall this pattern strongly suggests the time series are stationary now. However we can also perform a formal test whether our data is stationary or not. The augmented Dickey-Fuller test (ADF). P-values of the ADF for all log-returns are smaller than $10^{-12}$ even after correcting for multiple testing so we can safely assume the time series are stationary. 

\begin{figure}[h]
    \centering
    \figuretitle{ACF and PACF for prices of stock PG}
    \begin{adjustbox}{width=.95\textwidth,center}
    \input{figures/PG_autocorr_log_adjclose.pgf}
    \end{adjustbox}  
    \caption{Autocorrelation function (ACF) and partial autocorrelation function (PACF) for log-returns of PG. (For convenience, only one stock is shown. ACF and PACF for other stocks can be seen in the appendix in figure \ref{fig:acf_pacf_log_adjclose})}
    \label{fig:acf_pacf_log_adjclose_PG}
\end{figure}{}

\begin{table}[h!]
    \centering
    \figuretitle{Means of the log-returns for all Stocks}
    \begin{adjustbox}{width = 0.95\linewidth}
    \input{figures/means_fd_log_values2.tex}
    \end{adjustbox}
    \caption{}
    \label{tab:log return means}
\end{table}{}

\begin{figure}[H]
    \centering
    \figuretitle{ACF and PACF for log-returns of stock PG}
    \begin{adjustbox}{width=.95\textwidth,center}
    \input{figures/PG_autocorr_log_adjclose_fd.pgf}
    \end{adjustbox}
    \caption{Autocorrelation and partial autocorrelation for the log-returns of stock PG (For convenience, only one stock is shown. ACF and PACF for other stocks can be seen in the appendix in figure \ref{fig:all_autocorr_fd_log_adjclose}).}
    \label{fig:PG_autocorr_fd_log_adjclose}
\end{figure}{}

%Plot needed?: calculate returns and plot variance of returns. 







The data is, however, not quite normally distributed. While the mean of the log returns is close to zero, we can see by looking at figure \ref{fig:PG_qq_fd_log_adjclose} that the distribution has fat tails: extrem events appear more often than would be expected if the data was normally distributed. 

\begin{figure}[h]
    \centering
    \figuretitle{QQ-plot of log-returns of stock PG}
    \begin{adjustbox}{width=.9\textwidth,center}
    \includegraphics[]{figures/PG_log_adjclose_fd_and_qq.pdf}
    %\input{figures/PG_log_adjclose_fd_and_qq.pgf}
    \end{adjustbox}  
    \caption{QQ-Plot for log-returns of stock PG. QQ-plots for the other stocks can be seen in the Appendix in figure \ref{fig:all_qq_fd_log_adjclose}.}
    \label{fig:PG_qq_fd_log_adjclose}
\end{figure}{}

The data are also not homoscedastic. While stationarity implies that the unconditional variance is constant over time, the variance of the time series fluctuates conditional on past observations [Beschreibung nachgucken, QUELLE!]. This conditional heteroskedasticity is quite common in financial data. (SOURCE). The pattern can be observed in figure \ref{fig:PG_squared_log_returns}. Figure \ref{fig:ACF_selected_squared_log_returns} shows the ACF and PACF of the squared residuals of some selected stocks. The patterns indicate that at least some of the volatility can be modeled using time series approaches. 

\begin{figure}[h]
    \centering
    \figuretitle{Squared log-returns of Stock PG}
    \begin{adjustbox}{width=.95\textwidth,center}
    \input{figures/PG_squared_log_returns.pgf}
    \end{adjustbox}  
    \caption{Plot of squared log returns of stock PG. This serves as an approximation of the variance of the log returns, as $Var(x) = E [(x - E(x))^2$ and the mean of the log returns is close to zero. The pattern looks similar for all stocks, therefore only one is shown.}
    \label{fig:PG_squared_log_returns}
\end{figure}{}



\begin{figure}[H]
    \centering
    \figuretitle{ACF / PACF of Squared log-returns of Stocks MMM, GE, JNJ}
    \begin{adjustbox}{width=.95\textwidth,center}
    \input{figures/MMM_autocorr_log_adjclose_fd_squared.pgf}
    \end{adjustbox}
    \begin{adjustbox}{width=.95\textwidth,center}
    \input{figures/GE_autocorr_log_adjclose_fd_squared.pgf}
    \end{adjustbox}  
    \begin{adjustbox}{width=.95\textwidth,center}
    \input{figures/JNJ_autocorr_log_adjclose_fd_squared.pgf}
    \end{adjustbox}  
    \caption{ACF and PACF of squared residuals of stocks MMM, GE and JNJ. We see that some of the squared log-returns exhibit indeed autocorrelation, while others do less so. Strong autocorrelation implies that there is information about the future in the time series that can be modeled.}
    \label{fig:ACF_selected_squared_log_returns}
\end{figure}{}

