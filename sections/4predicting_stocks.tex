\chapter{Predicting Stocks}\label{ch:predictions}


\section{Predictions Using Machine Learning}

\section{Predictions Using Time Series}
\subsection{Idea/Process and Evaluation}
irgendwas in der Richtung: wir benutzen Time Series Modelle, machen Predictions und gucken uns am Ende dann den Mean Squared Error an. Sinnvollerweise immer die ersten 10 Perioden verwerfen, um den MSE vergleichbar zu machen zwischen allen Gruppen, auch denen, bei denen die ersten paar Perioden nicht definiert sind. 	
In-Sample vs. Out of Sample Prediction?
Do we need a Training, Validation and Test Period? Probably yes, since the respective next value was also used for validation, not only testing (we choose the model that minimizes MSE)

\subsection{Data Preparation}
\subsubsection*{The Original Data}

We can clearly see that the Data exhibits a trend. As Figure \ref{fig:cum_sd_all} shows the variance of the time series is not constant over time. 

\begin{figure}[H]
    \centering
    \begin{adjustbox}{width=.9\textwidth,center}
    \input{figures/cum_sd_all_stocks.pgf}
    \end{adjustbox}  
    \caption{Standard deviation for the time series of stock prices. The value of the graph at point t is calculated as the standard deviation of all recorded values of the respective stocks up to that point t.}
    \label{fig:cum_sd_all}
\end{figure}{}

\subsubsection*{The Log-Transformed Data}
We take the log of the data in order to stabilize the variance and convert the exponential trend to a linear trend. 

ALTERNATIVE: calculate returns and plot variance of returns. 

We look at autocorrelation and partial autocorrelation. In Figure \ref{fig:acf_pacf_log_adjclose_PG} only the ACF and PACF for one example, PG, is shown. The rest can be seen in the appendix in Figure \ref{fig:acf_pacf_log_adjclose}

\begin{figure}[h]
    \centering
    \begin{adjustbox}{width=.9\textwidth,center}
    \input{figures/PG_autocorr_log_adjclose.pgf}
    \end{adjustbox}  
    \caption{Autocorrelation and partial autocorrelation for the log of the adjusted closing prices for PG}
    \label{fig:acf_pacf_log_adjclose_PG}
\end{figure}{}


We can see a pattern of autocorrelations and a strong partial autocorrelation at lag 1 that indicated we should use differencing. 

\subsubsection*{First Difference of the Log-Transformed Data}
Therefore we apply first differencing to the data. 
We replot the data (shown in Figure \ref{fig:PG_fd_log_adjclose}. The entire data can be seen in the appendix in figure \ref{fig:all_fd_log_adjclose}

\begin{figure}[H]
    \centering
    \begin{adjustbox}{width=.9\textwidth,center}
    \input{figures/PG_fd_log_adjclose.pgf}
    \end{adjustbox}  
    \caption{First difference of log adjusted closing prices of PG}
    \label{fig:PG_fd_log_adjclose}
\end{figure}{}


Visually the data looks like white noise. Also the mean of those values is close to zero. The data now all seem to have mean zero and there is no trend visible. 
\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|}
    \hline
    \input{figures/means_fd_log_values.tex}
    \end{tabular}
    \caption{Caption}
    \label{tab:my_label}
\end{table}{}

Also ACF and PACF look more or less fine. For convenience, only ACF and PACF of PG are shown in figure \ref{fig:PG_autocorr_fd_log_adjclose}. The others are shown in the appendix in figure \ref{fig:all_autocorr_fd_log_adjclose}.
\begin{figure}[H]
    \centering
    \begin{adjustbox}{width=.9\textwidth,center}
    \input{figures/PG_autocorr_log_adjclose_fd.pgf}
    \end{adjustbox}  
    \caption{Autocorrelation and partial autocorrelation for the first difference of log adjusted closing prices for PG}
    \label{fig:PG_autocorr_fd_log_adjclose}
\end{figure}{}


\subsubsection*{Looking at QQ-Plots}
Looking at the QQ-plot (explanation) we see that the distribution has fat tails: some of the values are more extreme than we would have expected if the differenced log-values were randomly distributed. 

\begin{figure}[h]
    \centering
    \begin{adjustbox}{width=.9\textwidth,center}
    %\input{figures/all_qq_plot_fd_log_adjclose.pgf}
    \end{adjustbox}  
    \caption{QQ-Plots}
    \label{fig:all_qq_fd_log_adjclose}
\end{figure}{}







\subsection{Predictions With Random Walks}
A random walk follows (and is the same as AR(1)??? MA(1))
XXXXXXXX
Predictions for period t + 1 are therefore exactly the value at time t. --> We do that on the FD of log-values scale but we could also do it on the real scale

Confidence Intervals are computed as
XXXXXXXX

Fitting: 
Our Code fits an RW model, prediicts the next value, compares it to the real value for the MSE and then adds the true value to the time series used for predicting the next value. (we could have done this simpler, by just taking the values of the previous period as prediction for the current one. 

Figure: Plot Real vs. Predicted values. (Real values? or FD of log-Values?
Table: MSE

\subsection{Predictions With AR(x) Models}
AR(x) models follow
XXXXXX

Die Frage ist so ein bisschen, ob wir versuchen sollen, die ganze Zeitreihe mit einem einzelnen Fit zu beschreiben, oder ob wir jede Periode ein neues Modell fitten sollten. 
Table: MSE
Figure: Plot Real vs. Predicted values. (Real values? or FD of log-Values?

\subsection{Predictions With ARMA Models}
ARMA() follows
XXXXXXX


Auto-ARMA


\subsection{Predictions With GARCH Models}
GARCH follows 
XXXXXXX

Idea behind GARCH

predictions
fitting
confidence intervals
MSE

Plot: Squared time series



\subsection{Summary of Prediction with Time Series Models}
Table: MSE all
Figure: All predicted values?


\section{Hybrid Prediction}

\subsection{ARMAX Predictions}
ARMAX works like this: 
XXXXXX

Predictions
Confidence Intervals


Predictors can be 
- Using weather forecasts --> ARMAX
- Number of Tweets?
- Sentiments from Machine Learning Algorithm
- Predictions made by the Algorithm



\subsection{Weighted Average of Predictions}
a) of different time series models
b) of time series and ML models